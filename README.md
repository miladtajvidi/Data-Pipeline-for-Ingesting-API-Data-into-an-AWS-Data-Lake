# Data-Pipeline-for-Ingesting-API-Data-into-an-AWS-Data-Lake

## Project Overview
Designing and implementing a data pipeline that regularly ingests data from a public API into an AWS data lake. The data pipeline will ensure that the data is consistently updated and available for querying using AWS Athena. The project will showcase the use of various AWS services such as S3, Glue, and Athena, along with API integration and data pipeline design.



## Tools & Technologies
AWS S3: For storing raw and processed data<br>
AWS Glue: For ETL (Extract, Transform, Load) operations<br>
AWS Athena: For querying the data stored in S<br>
AWS Secrets Manager: For storing our API key securely<br>
AWS SNS: For notifications<br>
AWS CloudWAtch: For monitoring<br>
AWS Lambda: For serverless implementation<br>
Python: For scripting and API integration<br>
Public API: CoinBase API that provides data in a structured format (e.g., JSON, CSV).


## 1. [API Selection \& Setup](API%20Selection%20and%20Setup/README.md)

## 2. [AWS Setup](AWS%20Setup/README.md)

## 3. [Data Pipeline Design](Data%20Pipeline%20Design/README.md)

## 4. [Automation](Automation/README.md)

## 5. [Data Lake Management](Data%20Lake%20Management/README.md)

## 6. [Testing and Validation](Testing%20and%20Validation/README.md)
